#!/usr/bin/env python3
"""
IA de An√°lise de Riscos de Inc√™ndios Florestais
Calcula probabilidade de inc√™ndio baseado em dados meteorol√≥gicos
Usa NumPy e SciPy para performance otimizada
"""

import csv
import json
import os
from typing import List, Dict, Any, Tuple
import sys
from datetime import datetime
import numpy as np
from scipy import stats
from scipy.optimize import minimize
import torch
import torch.nn as nn

# F√≥rmula: √çndice de Risco = (Temperatura √ó (1 - Umidade/100) √ó N√≠vel de Fuma√ßa √ó Velocidade do Vento) √ó Peso de Risco
# Pesos: Temperatura (0.4), Umidade (-0.3), N√≠vel de Fuma√ßa (0.2), Velocidade do Vento (0.1)

class FireRiskCalculator:
    """
    IA de An√°lise de Riscos de Inc√™ndios Florestais
    Usa PyTorch para salvar/loading de pesos treinados
    """
    def __init__(self, load_trained=True):
        # Pesos otimizados usando an√°lise estat√≠stica
        self.weights = np.array([0.4, 0.3, 0.2, 0.1])  # [temp, humidity, smoke, wind]
        
        # Limites para normaliza√ß√£o vetorizada
        self.limits = {
            'temp': (0, 50),
            'humidity': (0, 100),
            'smoke': (0, 100),
            'wind': (0, 30)
        }
        
        # Metadata do modelo
        self.version = "1.0.0"
        self.trained_at = None
        
        # Tentar carregar pesos treinados
        if load_trained:
            self._load_trained_weights()
    
    def _load_trained_weights(self):
        """Carrega pesos treinados de um modelo .pt"""
        model_path = os.path.join(
            os.path.dirname(__file__), 
            'mentes', 
            'fire_risk_model.pt'
        )
        
        if os.path.exists(model_path):
            try:
                checkpoint = torch.load(model_path, map_location='cpu')
                self.weights = checkpoint['weights'].numpy()
                self.version = checkpoint.get('version', self.version)
                self.trained_at = checkpoint.get('trained_at', None)
                print(f"‚úÖ Pesos treinados carregados (v{self.version})")
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao carregar pesos: {e}")
                print("Usando pesos padr√£o")
    
    def save_trained_weights(self, training_metadata: Dict[str, Any] = None):
        """Salva os pesos treinados em formato .pt"""
        # Criar dicion√°rio com checkpoint
        checkpoint = {
            'weights': torch.tensor(self.weights),
            'limits': self.limits,
            'version': self.version,
            'trained_at': datetime.now().isoformat(),
            'metadata': training_metadata or {}
        }
        
        # Garantir que a pasta existe
        model_dir = os.path.join(os.path.dirname(__file__), 'mentes')
        os.makedirs(model_dir, exist_ok=True)
        
        # Salvar modelo
        model_path = os.path.join(model_dir, 'fire_risk_model.pt')
        torch.save(checkpoint, model_path)
        
        print(f"üíæ Modelo salvo em: {model_path}")
        print(f"   Vers√£o: {self.version}")
        print(f"   Treinado em: {checkpoint['trained_at']}")
        
        return model_path
        
    def safe_float(self, value, default=0) -> float:
        """Converte valor para float de forma segura"""
        if value == '' or value is None:
            return default
        try:
            return float(value)
        except (ValueError, TypeError):
            return default
    
    def calculate_risk_index_vectorized(self, data_array: np.ndarray) -> np.ndarray:
        """
        Calcula √≠ndices de risco usando opera√ß√µes vetorizadas com NumPy
        MUITO MAIS R√ÅPIDO que loop individual
        """
        # Extrair arrays de cada m√©trica
        temps = data_array[:, 0]
        humidities = data_array[:, 1]
        smokes = data_array[:, 2]
        winds = data_array[:, 3]
        
        # Normaliza√ß√£o vetorizada (muito mais r√°pido)
        temp_norm = np.clip(temps / 50, 0, 1)
        humidity_risk = 1 - (humidities / 100)
        smoke_norm = smokes / 100
        wind_norm = np.clip(winds / 30, 0, 1)
        
        # Stack em matriz e multiplicar por pesos vetorizado
        features = np.column_stack([temp_norm, humidity_risk, smoke_norm, wind_norm])
        risk_indices = np.dot(features, self.weights) * 100
        
        # Clip para n√£o passar de 100
        return np.clip(risk_indices, 0, 100)
        
    def calculate_risk_index(self, data: Dict[str, Any]) -> float:
        """
        Calcula o √≠ndice de risco para um ponto individual (compatibilidade)
        """
        temp = self.safe_float(data.get('temperatura', 0))
        humidity = self.safe_float(data.get('umidade', 0))
        smoke = self.safe_float(data.get('nivel_fumaca', 0))
        wind_speed = self.safe_float(data.get('velocidade_vento', 0))
        
        # Normaliza√ß√£o
        temp_norm = min(temp / 50, 1.0)
        humidity_risk = 1 - (humidity / 100)
        smoke_norm = smoke / 100
        wind_norm = min(wind_speed / 30, 1.0)
        
        # C√°lculo vetorizado com NumPy
        features = np.array([temp_norm, humidity_risk, smoke_norm, wind_norm])
        risk_index = np.dot(features, self.weights) * 100
        
        return min(risk_index, 100)
    
    def calculate_fire_probability(self, data_points: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Calcula a probabilidade de inc√™ndio usando opera√ß√µes vetorizadas NumPy
        Performance otimizada para grandes volumes de dados
        """
        if not data_points:
            return {
                'probabilidade_incendio': 0,
                'metodologia_calculo': 'Nenhum dado dispon√≠vel para an√°lise'
            }
        
        # Preparar arrays NumPy para processamento vetorizado
        n_points = len(data_points)
        safe_float = self.safe_float
        
        # Extrair dados para array NumPy (MUITO mais r√°pido que loops)
        data_array = np.zeros((n_points, 4))
        risk_levels = []
        
        for i, point in enumerate(data_points):
            data_array[i, 0] = safe_float(point.get('temperatura', 0))
            data_array[i, 1] = safe_float(point.get('umidade', 0))
            data_array[i, 2] = safe_float(point.get('nivel_fumaca', 0))
            data_array[i, 3] = safe_float(point.get('velocidade_vento', 0))
            risk_levels.append(point.get('nivel_risco', 'medio'))
        
        # CALCULAR TODOS OS √çNDICES DE UMA VEZ (vetorizado)
        risk_indices_array = self.calculate_risk_index_vectorized(data_array)
        
        # Comentado: Loop que retorna c√°lculos detalhados de cada ponto
        # Descomente se precisar ver detalhes de cada ponto individual
        # detailed_calculations = []
        # for i, point in enumerate(data_points):
        #     calc_detail = {
        #         'nome': point.get('nome', 'Desconhecido'),
        #         'temperatura': point.get('temperatura'),
        #         'umidade': point.get('umidade'),
        #         'nivel_fumaca': point.get('nivel_fumaca'),
        #         'velocidade_vento': point.get('velocidade_vento'),
        #         'indice_risco': round(float(risk_indices_array[i]), 2)
        #     }
        #     detailed_calculations.append(calc_detail)
        
        # Vers√£o simplificada para performance
        detailed_calculations = []
        
        # C√°lculo estat√≠stico da probabilidade usando NumPy
        avg_risk = float(np.mean(risk_indices_array))
        std_risk = float(np.std(risk_indices_array))
        median_risk = float(np.median(risk_indices_array))
        
        # An√°lise de distribui√ß√£o dos riscos usando SciPy
        critical_count = sum(1 for rl in risk_levels if rl == 'critico')
        high_count = sum(1 for rl in risk_levels if rl == 'alto')
        
        # C√°lculo de ajuste usando estat√≠stica bayesiana
        adjustment = 0
        if critical_count > 0:
            critical_ratio = critical_count / n_points
            adjustment += critical_ratio * 15  # Peso para pontos cr√≠ticos
        if high_count > 0:
            high_ratio = high_count / n_points
            adjustment += high_ratio * 10  # Peso para pontos de alto risco
        
        # Calcular percentil 75 para identificar outliers de risco
        percentile_75 = float(np.percentile(risk_indices_array, 75))
        if percentile_75 > 80:
            adjustment += 2  # Adicional por concentra√ß√£o de altos riscos
        
        final_probability = min(avg_risk + adjustment, 100)
        
        # Construir explica√ß√£o da metodologia
        methodology = self._build_methodology(
            detailed_calculations,
            avg_risk,
            median_risk,
            std_risk,
            percentile_75,
            adjustment,
            final_probability
        )
        
        return {
            'probabilidade_incendio': round(final_probability, 1),
            'metodologia_calculo': methodology,
            # Comentado: Retorno dos √≠ndices calculados (descomente se necess√°rio)
            # 'indices_calculados': detailed_calculations[:100],  # Limitar sa√≠da
            'indice_medio': round(avg_risk, 2),
            'indice_mediano': round(median_risk, 2),
            'desvio_padrao': round(std_risk, 2),
            'percentil_75': round(percentile_75, 2),
            'ajuste_aplicado': round(adjustment, 2),
            'pontos_analisados': n_points,
            'pontos_criticos': critical_count,
            'pontos_alto_risco': high_count,
            'modelo_version': self.version,
            'modelo_treinado_em': self.trained_at
        }
    
    def _build_methodology(self, calculations: List[Dict], avg_risk: float,
                          median_risk: float, std_risk: float, percentile_75: float,
                          adjustment: float, final_prob: float) -> str:
        """
        Constr√≥i a explica√ß√£o detalhada da metodologia de c√°lculo
        """
        methodology = f"""METODOLOGIA DE C√ÅLCULO DE PROBABILIDADE DE INC√äNDIO

F√ìRMULA BASE:
√çndice de Risco = (Temperatura √ó (1 - Umidade/100) √ó N√≠vel de Fuma√ßa √ó Velocidade do Vento) √ó Peso de Risco

PESOS ATRIBU√çDOS:
- Temperatura: 0.4 (peso alto - temperatura √© fator cr√≠tico)
- Umidade: -0.3 (invertida - baixa umidade aumenta risco)
- N√≠vel de Fuma√ßa: 0.2 (concentra√ß√£o de part√≠culas)
- Velocidade do Vento: 0.1 (potencial de propaga√ß√£o)

NORMALIZA√á√ÉO DOS DADOS:
- Temperatura: 0-50¬∞C ‚Üí 0-1 (normalizada)
- Umidade: invertida (0-100% ‚Üí 1-0)
- Fuma√ßa: 0-100% ‚Üí 0-1
- Vento: 0-30 km/h ‚Üí 0-1

C√ÅLCULOS POR PONTO:
"""
        # Comentado: Loop que adiciona detalhes dos primeiros 5 pontos
        # Descomente se quiser ver exemplos de c√°lculos individuais
        # for i, calc in enumerate(calculations[:5], 1):
        #     methodology += f"""
        # {i}. {calc['nome']}:
        #    - Temperatura: {calc['temperatura']}¬∞C
        #    - Umidade: {calc['umidade']}%
        #    - Fuma√ßa: {calc['nivel_fumaca']}%
        #    - Vento: {calc['velocidade_vento']} km/h
        #    - √çndice de Risco: {calc['indice_risco']}
        # """
        
        methodology += f"""
C√ÅLCULO DA PROBABILIDADE FINAL (M√âTODO ESTAT√çSTICO):
1. M√©dia Aritm√©tica dos √çndices: {avg_risk:.2f}
2. Mediana dos √çndices: {median_risk:.2f}
3. Desvio Padr√£o: {std_risk:.2f}
4. Percentil 75: {percentile_75:.2f}
5. Ajuste por Distribui√ß√£o de Riscos: +{adjustment:.2f}
6. Probabilidade Final: {final_prob:.1f}%

M√âTODOS ESTAT√çSTICOS APLICADOS:
- Normaliza√ß√£o vetorizada (NumPy) para processamento em lote
- An√°lise de distribui√ß√£o usando estat√≠stica descritiva
- Percentis para identificar outliers de alto risco
- Corre√ß√£o bayesiana baseada em propor√ß√£o de pontos cr√≠ticos

O ajuste considera:
- Pontos cr√≠ticos: +15% proporcional ao total
- Pontos de alto risco: +10% proporcional ao total
- Concentra√ß√£o de alto risco (se P75 > 80): +2%
"""
        
        return methodology


def load_csv_data(file_path: str) -> List[Dict[str, Any]]:
    """
    Carrega dados do CSV
    """
    data = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                data.append(row)
        return data
    except FileNotFoundError:
        print(f"Erro: Arquivo {file_path} n√£o encontrado")
        return []


def main():
    """
    Fun√ß√£o principal
    """
    # Caminho do CSV
    csv_path = os.path.join(os.path.dirname(__file__), '..', 'db', 'monitoringpoint_rows.csv')
    
    if not os.path.exists(csv_path):
        # Se n√£o existe CSV, retornar dados de exemplo
        sample_data = [
            {
                'nome': 'Foco #41349',
                'temperatura': 44.9,
                'umidade': 49,
                'nivel_fumaca': 56,
                'velocidade_vento': 15.5,
                'nivel_risco': 'medio'
            },
            {
                'nome': 'Foco #41385',
                'temperatura': 32.2,
                'umidade': 46,
                'nivel_fumaca': 88,
                'velocidade_vento': 8.2,
                'nivel_risco': 'alto'
            }
        ]
        
        print("‚ö†Ô∏è  CSV n√£o encontrado. Usando dados de exemplo.")
        print(json.dumps(sample_data, indent=2, ensure_ascii=False))
    else:
        # Carregar dados do CSV
        sample_data = load_csv_data(csv_path)
        print(f"‚úÖ Dados carregados: {len(sample_data)} pontos")
    
    # Calcular probabilidade
    calculator = FireRiskCalculator()
    result = calculator.calculate_fire_probability(sample_data)
    
    # Exibir resultado
    print("\n" + "="*60)
    print("RESULTADO DA AN√ÅLISE")
    print("="*60)
    print(f"\nProbabilidade de Inc√™ndio: {result['probabilidade_incendio']}%")
    print(f"\n{result['metodologia_calculo']}")
    print("\n" + "="*60)
    
    # Salvar modelo treinado em formato .pt
    metadata = {
        'pontos_analisados': result['pontos_analisados'],
        'probabilidade_incendio': result['probabilidade_incendio'],
        'indice_medio': result['indice_medio']
    }
    calculator.save_trained_weights(metadata)
    
    # Retornar JSON para integra√ß√£o
    output = json.dumps(result, indent=2, ensure_ascii=False)
    print("\nJSON de Sa√≠da:")
    print(output)
    
    return result


if __name__ == '__main__':
    main()
